# -*- coding: utf-8 -*-
"""Trabalho_prático_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ClTOd3X13PYOD_Dkkw_1xdG7H8SpIDCr

# **Bootcamp Desenvolvedor Python**

**Trabalho Prático - módulo 4**
"""

#Importando as bibliotecas

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from mlxtend.plotting import plot_confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, accuracy_score

#Carregando o dataset

df = pd.read_csv('/content/datasets_diabetes.csv')

#Verificando os cinco primeiros registros do dataset
df.head()

#Verificando se há valores nulos

df.info()

#Verificando a média da coluna 'Age'
#33.240885

df.describe()

#Aprendizagem supervisionada

#Separando as features (dados de entrada)
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

#Definindo as features (X) e o target (y)
X = df[features]
y = df.Outcome #coluna alvo

# Utilizando as entradas e a saída como apresentado no enunciado do trabalho, quantos valores da variável de saída “1” existem no conjunto de dados? 

df['Outcome'].value_counts()

#Normalizando os dados de entrada

normaliza = MinMaxScaler()
entradas_normalizadas = normaliza.fit_transform(X) #X: dados de entrada

#Separando 30% da amostra para dados de teste/validação

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=42)

#Utilizando o método “train_test_split” como apresentado no enunciado, quantas instâncias (linhas) foram selecionadas para o conjunto de dados de treinamento do modelo? 

X_train.count()

#KNN: Vizinho mais próximo
#Cria o classificador a partir de 5 vizinhos

clf_KNN = KNeighborsClassifier(n_neighbors=5)

#Aplica o classificador na amostra de treinamento

clf_KNN.fit(X_train, y_train)

#Testar o modelo, realizando a predição com a amostra de testes

pred = clf_KNN.predict(X_test)

#Medindo o desempenho desse algoritmo através da plotagem da Matriz de Confusão entre a variável conhecida y_test e a predita pred

matriz_confusao = confusion_matrix(y_test, pred)

#Plotando a matriz de confusão para análise

fig, ax = plot_confusion_matrix(conf_mat = matriz_confusao)
plt.show()

#Explicação: 159 (114 + 45) predições corretas (y_test = pred) e 72 (35 + 37) erradas (true label diferente de predicted label)
#68,83% de acerto, 31,16% de erro

#Após dividir as colunas do dataframe entre entrada e saída, aplicar a normalização dos dados como apresentado no enunciado (MinMaxScaler()) e dividir esses dados entre treinamento e teste, aplique o algoritmo KNN. Qual é, aproximadamente, a acurácia do modelo? 

target_names = ['0(não diabético)', '1(diabético)']
print(classification_report(y_test, pred, target_names=target_names))

"""Explicação:

Acurácia: indica uma performance geral do modelo. Dentre todas as classificações, quantas o modelo classificou corretamente;

Precisão: dentre todas as classificações de classe Positivo que o modelo fez, quantas estão corretas;

Recall/Revocação/Sensibilidade: dentre todas as situações de classe Positivo como valor esperado, quantas estão corretas;

F1-Score: média harmônica entre precisão e recall.
"""

#Usando árvore de decisão

clf_arvore=DecisionTreeClassifier(random_state=1)

#Aplica o classificador na amostra de treinamento

clf_arvore.fit(X_train, y_train)

#Realizando a predição na amostra de testes

pred_tree=clf_arvore.predict(X_test)

#Medindo o desempenho desse algoritmo através da plotagem da Matriz de Confusão entre a variável conhecida y_test e a predita pred

matriz_confusao = confusion_matrix(y_test, pred_tree)

#Plotando a matriz de confusão para análise

fig, ax = plot_confusion_matrix(conf_mat = matriz_confusao)
plt.show()

#Explicação: 160 predições corretas (y_test = pred) e 71 erradas (true label diferente de predicted label)
#69,26% de acerto, 30,74% de erro

#Após dividir as colunas do dataframe entre entrada e saída, aplicar a normalização dos dados como apresentado no enunciado (MinMaxScaler()) e dividir esses dados entre treinamento e teste, aplique o algoritmo Árvore de Decisão. Qual é, aproximadamente, a acurácia do modelo? 

target_names = ['0(não diabético)', '1(diabético)']
print(classification_report(y_test, pred_tree, target_names=target_names))

#Usando AlgoritmoFlorestaRandômica

clf_floresta=RandomForestClassifier(max_depth=10,random_state=1)

#Aplicando o classificador na amostra de treinamento

clf_floresta.fit(X_train,y_train)

#Realizando a predição na amostra de testes

pred_floresta=clf_floresta.predict(X_test)

#Medindo o desempenho desse algoritmo através da plotagem da Matriz de Confusão entre a variável conhecida y_test e a predita pred

matriz_confusao = confusion_matrix(y_test, pred_floresta)

#Plotando a matriz de confusão para análise

fig, ax = plot_confusion_matrix(conf_mat = matriz_confusao)
plt.show()

#Após dividir as colunas do dataframe entre entrada e saída, aplicar a normalização dos dados como apresentado no enunciado (MinMaxScaler()) e dividir esses dados entre treinamento e teste, aplique o algoritmo Floresta Randômica. Qual é, aproximadamente, a acurácia do modelo? 

target_names = ['0(não diabético)', '1(diabético)']
print(classification_report(y_test, pred_floresta, target_names=target_names))

#Usando o AlgoritmoSVM

clf_svm=SVC(gamma='auto',random_state=1)

#Aplicando o classificador na amostra de treinamento

clf_svm.fit(X_train,y_train)

#Realizando predição

pred_svc=clf_svm.predict(X_test)

#Medindo o desempenho desse algoritmo através da plotagem da Matriz de Confusão entre a variável conhecida y_test e a predita pred

matriz_confusao = confusion_matrix(y_test, pred_svc)

#Plotando a matriz de confusão para análise

fig, ax = plot_confusion_matrix(conf_mat = matriz_confusao)
plt.show()

#Após dividir as colunas do dataframe entre entrada e saída, aplicar a normalização dos dados como apresentado no enunciado (MinMaxScaler()) e dividir os dados entre treinamento e teste, aplique o algoritmo SVM. Qual é, aproximadamente, a acurácia do modelo? 

target_names = ['0(não diabético)', '1(diabético)']
print(classification_report(y_test, pred_svc, target_names=target_names))

#Usando AlgoritmoRedeMLP

clf_mlp=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5,5),random_state=1)

#Aplicando o classificador na amostra de treinamento

clf_mlp.fit(X_train, y_train)

#Realizando a predição na amostra de teste

pred_rede = clf_mlp.predict(X_test)

#Aplicando os resultados na matriz de confusão

matriz_confusao = confusion_matrix(y_test, pred_rede)

#Visualizando os resultados

fig, ax = plot_confusion_matrix(conf_mat = matriz_confusao)
plt.show()

#Após dividir as colunas do dataframe entre entrada e saída, aplicar a normalização dos dados como apresentado no enunciado (MinMaxScaler()) e dividir os dados entre treinamento e teste, aplique o algoritmo MLP. Qual é, aproximadamente, a acurácia do modelo? 

print(classification_report(y_test, pred_svc, target_names=target_names))

"""Acurácias:

- KNN: 0,6883
- Árvore de decisão: 0,6926
- Floresta randômica: 0,74
- SVM: 0,65 (atenção mais abaixo)
- MLP: 0,65 (atenção mais abaixo)
"""

#Implemente o código 1 presente no enunciado do trabalho. Sobre esse código, é INCORRETO afirmar que: 

import threading
import time
from random import randint

def funcao_1(num):
    n=num
    while n>0:
      n-=1
      print('n_1: {}.format(n)')
      time.sleep(randint(0,2))

def funcao_2(num):
    n=num
    while n>100:
      n+=1
      print('n_2: {}.format(n)')
      time.sleep(randint(0,2))

if __name__ == "__main__":

    t1 = threading.Thread(target = funcao_1, args=(100,))
    t2 = threading.Thread(target = funcao_2, args=(0,))

    t1.start()
    t2.start()

    t1.join()
    t2.join()

    print('Fim!')

"""A forma como dividimos os dados de entrada da saída influenciam bastante. Anteriormente dividimos entre features (X) e a coluna alvo y.
Agora vamos dividir de forma diferente.

Reiniciar ambiente de execução!
"""

# Transformando os dados em array

entradas = df.iloc[:, :-1].values  #dados de entrada (todas as linhas, e todas as colunas menos a última)
saida = df.iloc[:, 8].values  # saídas ou target (todas as linhas, coluna 8, que é a última)

#Normalizando os dados de entrada

normaliza = MinMaxScaler()
entradas_normalizadas = normaliza.fit_transform(entradas)

#Separando 30% da amostra para dados de teste/validação

X_train, X_test, y_train, y_test = train_test_split(entradas_normalizadas, saida, test_size=0.30,random_state=42);

clf_svm=SVC(gamma='auto',random_state=1)

# Realiza o treinamento do classificador
clf_svm = clf_svm.fit(X_train,y_train)

#Realiza a previsão de classificação 
y_pred = clf_svm.predict(X_test)

# Avaliando a Acurácia

print("Acurácia: {}".format(accuracy_score(y_test, y_pred)))
print(classification_report(y_test, y_pred))

clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 5), random_state=1)

# Realiza o treinamento do classificador
clf_mlp = clf_mlp.fit(X_train,y_train)

#Realiza a previsão de classificação 
y_pred = clf_mlp.predict(X_test)

# Avaliando a Acurácia

print("Acurácia: {}".format(accuracy_score(y_test, y_pred)))
print(classification_report(y_test, y_pred))